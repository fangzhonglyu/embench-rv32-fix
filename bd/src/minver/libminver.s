	.file	"libminver.c"
	.option nopic
	.attribute arch, "rv32i2p1_m2p0_zicsr2p0_zifencei2p0_zmmul1p0"
	.attribute unaligned_access, 0
	.attribute stack_align, 16
	.text
	.data
	.align	2
	.type	a_ref, @object
	.size	a_ref, 36
a_ref:
	.word	1077936128
	.word	-1061158912
	.word	1088421888
	.word	1091567616
	.word	0
	.word	-1063256064
	.word	1084227584
	.word	-1056964608
	.word	1086324736
	.align	2
	.type	b, @object
	.size	b, 36
b:
	.word	-1069547520
	.word	0
	.word	1073741824
	.word	1077936128
	.word	-1073741824
	.word	0
	.word	0
	.word	1073741824
	.word	-1069547520
	.local	a
	.comm	a,36,4
	.local	c
	.comm	c,36,4
	.local	d
	.comm	d,36,4
	.local	det
	.comm	det,4,4
	.text
	.align	2
	.type	minver_fabs, @function
minver_fabs:
	addi	sp,sp,-48
	sw	ra,44(sp)
	sw	s0,40(sp)
	addi	s0,sp,48
	sw	a0,-36(s0)
	mv	a1,zero
	lw	a0,-36(s0)
	call	__gesf2
	mv	a5,a0
	blt	a5,zero,.L7
	lw	a5,-36(s0)
	sw	a5,-20(s0)
	j	.L4
.L7:
	lw	a4,-36(s0)
	li	a5,-2147483648
	xor	a5,a4,a5
	sw	a5,-20(s0)
.L4:
	lw	a5,-20(s0)
	mv	a0,a5
	lw	ra,44(sp)
	lw	s0,40(sp)
	addi	sp,sp,48
	jr	ra
	.size	minver_fabs, .-minver_fabs
	.align	2
	.globl	mmul
	.type	mmul, @function
mmul:
	addi	sp,sp,-64
	sw	ra,60(sp)
	sw	s0,56(sp)
	addi	s0,sp,64
	sw	a0,-52(s0)
	sw	a1,-56(s0)
	sw	a2,-60(s0)
	sw	a3,-64(s0)
	lw	a5,-52(s0)
	sw	a5,-36(s0)
	lw	a5,-64(s0)
	sw	a5,-40(s0)
	lw	a5,-36(s0)
	ble	a5,zero,.L9
	lw	a5,-60(s0)
	ble	a5,zero,.L9
	lw	a5,-40(s0)
	ble	a5,zero,.L9
	lw	a4,-56(s0)
	lw	a5,-60(s0)
	beq	a4,a5,.L10
.L9:
	li	a5,999
	j	.L11
.L10:
	sw	zero,-20(s0)
	j	.L12
.L17:
	sw	zero,-24(s0)
	j	.L13
.L16:
	mv	a5,zero
	sw	a5,-32(s0)
	sw	zero,-28(s0)
	j	.L14
.L15:
	lui	a5,%hi(a)
	addi	a3,a5,%lo(a)
	lw	a4,-20(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-28(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a3,a5
	lw	a2,0(a5)
	lui	a5,%hi(b)
	addi	a3,a5,%lo(b)
	lw	a4,-28(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-24(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a3,a5
	lw	a5,0(a5)
	mv	a1,a5
	mv	a0,a2
	call	__mulsf3
	mv	a5,a0
	mv	a1,a5
	lw	a0,-32(s0)
	call	__addsf3
	mv	a5,a0
	sw	a5,-32(s0)
	lw	a5,-28(s0)
	addi	a5,a5,1
	sw	a5,-28(s0)
.L14:
	lw	a4,-28(s0)
	lw	a5,-60(s0)
	blt	a4,a5,.L15
	lui	a5,%hi(c)
	addi	a3,a5,%lo(c)
	lw	a4,-20(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-24(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a3,a5
	lw	a4,-32(s0)
	sw	a4,0(a5)
	lw	a5,-24(s0)
	addi	a5,a5,1
	sw	a5,-24(s0)
.L13:
	lw	a4,-24(s0)
	lw	a5,-40(s0)
	blt	a4,a5,.L16
	lw	a5,-20(s0)
	addi	a5,a5,1
	sw	a5,-20(s0)
.L12:
	lw	a4,-20(s0)
	lw	a5,-36(s0)
	blt	a4,a5,.L17
	li	a5,0
.L11:
	mv	a0,a5
	lw	ra,60(sp)
	lw	s0,56(sp)
	addi	sp,sp,64
	jr	ra
	.size	mmul, .-mmul
	.align	2
	.globl	minver
	.type	minver, @function
minver:
	addi	sp,sp,-2032
	sw	ra,2028(sp)
	sw	s0,2024(sp)
	sw	s1,2020(sp)
	addi	s0,sp,2032
	addi	sp,sp,-48
	li	a5,-4096
	addi	a5,a5,-16
	add	a5,a5,s0
	sw	a0,2044(a5)
	li	a5,-4096
	addi	a5,a5,-16
	add	a5,a5,s0
	sw	a1,2040(a5)
	li	a5,-4096
	addi	a5,a5,-16
	add	a5,a5,s0
	sw	a2,2036(a5)
	mv	a5,zero
	sw	a5,-36(s0)
	sw	zero,-32(s0)
	li	a5,-4096
	addi	a5,a5,-16
	add	a5,a5,s0
	lw	a4,2044(a5)
	li	a5,1
	ble	a4,a5,.L19
	li	a5,-4096
	addi	a5,a5,-16
	add	a5,a5,s0
	lw	a4,2044(a5)
	li	a5,500
	bgt	a4,a5,.L19
	li	a5,-4096
	addi	a5,a5,-16
	add	a5,a5,s0
	mv	a1,zero
	lw	a0,2036(a5)
	call	__lesf2
	mv	a5,a0
	bgt	a5,zero,.L55
.L19:
	li	a5,999
	j	.L51
.L55:
	lui	a5,%hi(.LC0)
	lw	a5,%lo(.LC0)(a5)
	sw	a5,-44(s0)
	sw	zero,-20(s0)
	j	.L23
.L24:
	lw	a4,-20(s0)
	addi	a5,s0,-2048
	addi	a5,a5,-16
	slli	a4,a4,2
	add	a5,a4,a5
	lw	a4,-20(s0)
	sw	a4,0(a5)
	lw	a5,-20(s0)
	addi	a5,a5,1
	sw	a5,-20(s0)
.L23:
	li	a5,-4096
	addi	a5,a5,-16
	add	a5,a5,s0
	lw	a4,-20(s0)
	lw	a5,2044(a5)
	blt	a4,a5,.L24
	sw	zero,-28(s0)
	j	.L25
.L44:
	mv	a5,zero
	sw	a5,-40(s0)
	lw	a5,-28(s0)
	sw	a5,-20(s0)
	j	.L26
.L29:
	lui	a5,%hi(a)
	addi	a3,a5,%lo(a)
	lw	a4,-20(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-28(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a3,a5
	lw	a5,0(a5)
	mv	a0,a5
	call	minver_fabs
	sw	a0,-36(s0)
	lw	a1,-40(s0)
	lw	a0,-36(s0)
	call	__gtsf2
	mv	a5,a0
	ble	a5,zero,.L27
	lw	a5,-36(s0)
	sw	a5,-40(s0)
	lw	a5,-20(s0)
	sw	a5,-32(s0)
.L27:
	lw	a5,-20(s0)
	addi	a5,a5,1
	sw	a5,-20(s0)
.L26:
	li	a5,-4096
	addi	a5,a5,-16
	add	a5,a5,s0
	lw	a4,-20(s0)
	lw	a5,2044(a5)
	blt	a4,a5,.L29
	lui	a5,%hi(a)
	addi	a3,a5,%lo(a)
	lw	a4,-32(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-28(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a3,a5
	lw	a5,0(a5)
	sw	a5,-56(s0)
	lw	a0,-56(s0)
	call	minver_fabs
	sw	a0,-60(s0)
	li	a5,-4096
	addi	a5,a5,-16
	add	a5,a5,s0
	lw	a1,2036(a5)
	lw	a0,-60(s0)
	call	__lesf2
	mv	a5,a0
	bgt	a5,zero,.L56
	lui	a5,%hi(det)
	lw	a4,-44(s0)
	sw	a4,%lo(det)(a5)
	li	a5,1
	j	.L51
.L56:
	lw	a1,-56(s0)
	lw	a0,-44(s0)
	call	__mulsf3
	mv	a5,a0
	sw	a5,-44(s0)
	li	a5,-4096
	addi	a5,a5,-16
	add	a5,a5,s0
	lw	a4,-28(s0)
	lw	a5,2040(a5)
	mul	a5,a4,a5
	sw	a5,-52(s0)
	li	a5,-4096
	addi	a5,a5,-16
	add	a5,a5,s0
	lw	a4,-32(s0)
	lw	a5,2040(a5)
	mul	a5,a4,a5
	sw	a5,-64(s0)
	lw	a4,-32(s0)
	lw	a5,-28(s0)
	beq	a4,a5,.L32
	lw	a4,-36(s0)
	li	a5,-2147483648
	xor	a5,a4,a5
	sw	a5,-44(s0)
	lw	a4,-28(s0)
	addi	a5,s0,-2048
	addi	a5,a5,-16
	slli	a4,a4,2
	add	a5,a4,a5
	lw	a5,0(a5)
	sw	a5,-48(s0)
	lw	a4,-32(s0)
	addi	a5,s0,-2048
	addi	a5,a5,-16
	slli	a4,a4,2
	add	a5,a4,a5
	lw	a4,0(a5)
	lw	a3,-28(s0)
	addi	a5,s0,-2048
	addi	a5,a5,-16
	slli	a3,a3,2
	add	a5,a3,a5
	sw	a4,0(a5)
	lw	a4,-32(s0)
	addi	a5,s0,-2048
	addi	a5,a5,-16
	slli	a4,a4,2
	add	a5,a4,a5
	lw	a4,-48(s0)
	sw	a4,0(a5)
	sw	zero,-24(s0)
	j	.L33
.L34:
	lui	a5,%hi(a)
	addi	a3,a5,%lo(a)
	lw	a4,-28(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-24(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a3,a5
	lw	a5,0(a5)
	sw	a5,-36(s0)
	lui	a5,%hi(a)
	addi	a3,a5,%lo(a)
	lw	a4,-32(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-24(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a3,a5
	lw	a3,0(a5)
	lui	a5,%hi(a)
	addi	a2,a5,%lo(a)
	lw	a4,-28(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-24(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a2,a5
	sw	a3,0(a5)
	lui	a5,%hi(a)
	addi	a3,a5,%lo(a)
	lw	a4,-32(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-24(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a3,a5
	lw	a4,-36(s0)
	sw	a4,0(a5)
	lw	a5,-24(s0)
	addi	a5,a5,1
	sw	a5,-24(s0)
.L33:
	li	a5,-4096
	addi	a5,a5,-16
	add	a5,a5,s0
	lw	a4,-24(s0)
	lw	a5,2044(a5)
	blt	a4,a5,.L34
.L32:
	sw	zero,-20(s0)
	j	.L35
.L36:
	lui	a5,%hi(a)
	addi	a3,a5,%lo(a)
	lw	a4,-28(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-20(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a3,a5
	lw	a5,0(a5)
	lw	a1,-56(s0)
	mv	a0,a5
	call	__divsf3
	mv	a5,a0
	mv	a2,a5
	lui	a5,%hi(a)
	addi	a3,a5,%lo(a)
	lw	a4,-28(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-20(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a3,a5
	sw	a2,0(a5)
	lw	a5,-20(s0)
	addi	a5,a5,1
	sw	a5,-20(s0)
.L35:
	li	a5,-4096
	addi	a5,a5,-16
	add	a5,a5,s0
	lw	a4,-20(s0)
	lw	a5,2044(a5)
	blt	a4,a5,.L36
	sw	zero,-20(s0)
	j	.L37
.L43:
	lw	a4,-20(s0)
	lw	a5,-28(s0)
	beq	a4,a5,.L38
	li	a5,-4096
	addi	a5,a5,-16
	add	a5,a5,s0
	lw	a4,-20(s0)
	lw	a5,2040(a5)
	mul	a5,a4,a5
	sw	a5,-64(s0)
	lui	a5,%hi(a)
	addi	a3,a5,%lo(a)
	lw	a4,-20(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-28(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a3,a5
	lw	a5,0(a5)
	sw	a5,-36(s0)
	mv	a1,zero
	lw	a0,-36(s0)
	call	__nesf2
	mv	a5,a0
	beq	a5,zero,.L38
	sw	zero,-24(s0)
	j	.L40
.L42:
	lw	a4,-24(s0)
	lw	a5,-28(s0)
	beq	a4,a5,.L41
	lui	a5,%hi(a)
	addi	a3,a5,%lo(a)
	lw	a4,-20(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-24(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a3,a5
	lw	s1,0(a5)
	lui	a5,%hi(a)
	addi	a3,a5,%lo(a)
	lw	a4,-28(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-24(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a3,a5
	lw	a5,0(a5)
	lw	a1,-36(s0)
	mv	a0,a5
	call	__mulsf3
	mv	a5,a0
	mv	a1,a5
	mv	a0,s1
	call	__subsf3
	mv	a5,a0
	mv	a2,a5
	lui	a5,%hi(a)
	addi	a3,a5,%lo(a)
	lw	a4,-20(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-24(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a3,a5
	sw	a2,0(a5)
.L41:
	lw	a5,-24(s0)
	addi	a5,a5,1
	sw	a5,-24(s0)
.L40:
	li	a5,-4096
	addi	a5,a5,-16
	add	a5,a5,s0
	lw	a4,-24(s0)
	lw	a5,2044(a5)
	blt	a4,a5,.L42
	lw	a4,-36(s0)
	li	a5,-2147483648
	xor	a5,a4,a5
	lw	a1,-56(s0)
	mv	a0,a5
	call	__divsf3
	mv	a5,a0
	mv	a2,a5
	lui	a5,%hi(a)
	addi	a3,a5,%lo(a)
	lw	a4,-20(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-28(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a3,a5
	sw	a2,0(a5)
.L38:
	lw	a5,-20(s0)
	addi	a5,a5,1
	sw	a5,-20(s0)
.L37:
	li	a5,-4096
	addi	a5,a5,-16
	add	a5,a5,s0
	lw	a4,-20(s0)
	lw	a5,2044(a5)
	blt	a4,a5,.L43
	lui	a5,%hi(.LC0)
	lw	a1,-56(s0)
	lw	a0,%lo(.LC0)(a5)
	call	__divsf3
	mv	a5,a0
	mv	a3,a5
	lui	a5,%hi(a)
	addi	a4,a5,%lo(a)
	lw	a5,-28(s0)
	slli	a5,a5,4
	add	a5,a4,a5
	sw	a3,0(a5)
	lw	a5,-28(s0)
	addi	a5,a5,1
	sw	a5,-28(s0)
.L25:
	li	a5,-4096
	addi	a5,a5,-16
	add	a5,a5,s0
	lw	a4,-28(s0)
	lw	a5,2044(a5)
	blt	a4,a5,.L44
	sw	zero,-20(s0)
	j	.L45
.L50:
	lw	a4,-20(s0)
	addi	a5,s0,-2048
	addi	a5,a5,-16
	slli	a4,a4,2
	add	a5,a4,a5
	lw	a5,0(a5)
	sw	a5,-28(s0)
	lw	a4,-28(s0)
	lw	a5,-20(s0)
	beq	a4,a5,.L58
	lw	a4,-28(s0)
	addi	a5,s0,-2048
	addi	a5,a5,-16
	slli	a4,a4,2
	add	a5,a4,a5
	lw	a5,0(a5)
	sw	a5,-48(s0)
	lw	a4,-20(s0)
	addi	a5,s0,-2048
	addi	a5,a5,-16
	slli	a4,a4,2
	add	a5,a4,a5
	lw	a4,0(a5)
	lw	a3,-28(s0)
	addi	a5,s0,-2048
	addi	a5,a5,-16
	slli	a3,a3,2
	add	a5,a3,a5
	sw	a4,0(a5)
	lw	a4,-20(s0)
	addi	a5,s0,-2048
	addi	a5,a5,-16
	slli	a4,a4,2
	add	a5,a4,a5
	lw	a4,-48(s0)
	sw	a4,0(a5)
	sw	zero,-24(s0)
	j	.L48
.L49:
	li	a5,-4096
	addi	a5,a5,-16
	add	a5,a5,s0
	lw	a4,-24(s0)
	lw	a5,2040(a5)
	mul	a5,a4,a5
	sw	a5,-52(s0)
	lui	a5,%hi(a)
	addi	a3,a5,%lo(a)
	lw	a4,-28(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-20(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a3,a5
	lw	a5,0(a5)
	sw	a5,-36(s0)
	lui	a5,%hi(a)
	addi	a4,a5,%lo(a)
	lw	a5,-28(s0)
	slli	a5,a5,4
	add	a5,a4,a5
	lw	a3,0(a5)
	lui	a5,%hi(a)
	addi	a2,a5,%lo(a)
	lw	a4,-28(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-20(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a2,a5
	sw	a3,0(a5)
	lui	a5,%hi(a)
	addi	a4,a5,%lo(a)
	lw	a5,-28(s0)
	slli	a5,a5,4
	add	a5,a4,a5
	lw	a4,-36(s0)
	sw	a4,0(a5)
	lw	a5,-24(s0)
	addi	a5,a5,1
	sw	a5,-24(s0)
.L48:
	li	a5,-4096
	addi	a5,a5,-16
	add	a5,a5,s0
	lw	a4,-24(s0)
	lw	a5,2044(a5)
	blt	a4,a5,.L49
	j	.L50
.L58:
	nop
	lw	a5,-20(s0)
	addi	a5,a5,1
	sw	a5,-20(s0)
.L45:
	li	a5,-4096
	addi	a5,a5,-16
	add	a5,a5,s0
	lw	a4,-20(s0)
	lw	a5,2044(a5)
	blt	a4,a5,.L50
	lui	a5,%hi(det)
	lw	a4,-44(s0)
	sw	a4,%lo(det)(a5)
	li	a5,0
.L51:
	mv	a0,a5
	addi	sp,sp,48
	lw	ra,2028(sp)
	lw	s0,2024(sp)
	lw	s1,2020(sp)
	addi	sp,sp,2032
	jr	ra
	.size	minver, .-minver
	.align	2
	.globl	verify_benchmark
	.type	verify_benchmark, @function
verify_benchmark:
	addi	sp,sp,-48
	sw	ra,44(sp)
	sw	s0,40(sp)
	sw	s1,36(sp)
	addi	s0,sp,48
	sw	a0,-36(s0)
	lui	a5,%hi(.LC1)
	lw	a5,%lo(.LC1)(a5)
	sw	a5,-28(s0)
	sw	zero,-20(s0)
	j	.L60
.L68:
	sw	zero,-24(s0)
	j	.L61
.L67:
	lui	a5,%hi(c)
	addi	a3,a5,%lo(c)
	lw	a4,-20(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-24(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a3,a5
	lw	a2,0(a5)
	lui	a5,%hi(c_exp.1)
	addi	a3,a5,%lo(c_exp.1)
	lw	a4,-20(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-24(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a3,a5
	lw	a5,0(a5)
	mv	a1,a5
	mv	a0,a2
	call	__subsf3
	mv	a5,a0
	mv	a4,a5
	li	a5,-2147483648
	addi	a5,a5,-1
	and	a5,a4,a5
	mv	a0,a5
	call	__extendsfdf2
	mv	a4,a0
	mv	a5,a1
	li	s1,1
	lui	a3,%hi(.LC2)
	lw	a2,%lo(.LC2)(a3)
	lw	a3,%lo(.LC2+4)(a3)
	mv	a0,a4
	mv	a1,a5
	call	__ltdf2
	mv	a5,a0
	blt	a5,zero,.L62
	li	s1,0
.L62:
	andi	a5,s1,0xff
	xori	a5,a5,1
	andi	a5,a5,0xff
	bne	a5,zero,.L63
	lui	a5,%hi(d)
	addi	a3,a5,%lo(d)
	lw	a4,-20(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-24(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a3,a5
	lw	a2,0(a5)
	lui	a5,%hi(d_exp.0)
	addi	a3,a5,%lo(d_exp.0)
	lw	a4,-20(s0)
	mv	a5,a4
	slli	a5,a5,1
	add	a5,a5,a4
	lw	a4,-24(s0)
	add	a5,a5,a4
	slli	a5,a5,2
	add	a5,a3,a5
	lw	a5,0(a5)
	mv	a1,a5
	mv	a0,a2
	call	__subsf3
	mv	a5,a0
	mv	a4,a5
	li	a5,-2147483648
	addi	a5,a5,-1
	and	a5,a4,a5
	mv	a0,a5
	call	__extendsfdf2
	mv	a4,a0
	mv	a5,a1
	li	s1,1
	lui	a3,%hi(.LC2)
	lw	a2,%lo(.LC2)(a3)
	lw	a3,%lo(.LC2+4)(a3)
	mv	a0,a4
	mv	a1,a5
	call	__ltdf2
	mv	a5,a0
	blt	a5,zero,.L64
	li	s1,0
.L64:
	andi	a5,s1,0xff
	xori	a5,a5,1
	andi	a5,a5,0xff
	beq	a5,zero,.L65
.L63:
	li	a5,0
	j	.L66
.L65:
	lw	a5,-24(s0)
	addi	a5,a5,1
	sw	a5,-24(s0)
.L61:
	lw	a4,-24(s0)
	li	a5,2
	ble	a4,a5,.L67
	lw	a5,-20(s0)
	addi	a5,a5,1
	sw	a5,-20(s0)
.L60:
	lw	a4,-20(s0)
	li	a5,2
	ble	a4,a5,.L68
	lui	a5,%hi(det)
	lw	a5,%lo(det)(a5)
	mv	a0,a5
	call	__extendsfdf2
	mv	a4,a0
	mv	a5,a1
	lui	a3,%hi(.LC3)
	lw	a2,%lo(.LC3)(a3)
	lw	a3,%lo(.LC3+4)(a3)
	mv	a0,a4
	mv	a1,a5
	call	__adddf3
	mv	a4,a0
	mv	a5,a1
	mv	a0,a4
	mv	a1,a5
	call	__truncdfsf2
	mv	a4,a0
	li	a5,-2147483648
	addi	a5,a5,-1
	and	a5,a4,a5
	mv	a0,a5
	call	__extendsfdf2
	mv	a4,a0
	mv	a5,a1
	li	s1,1
	lui	a3,%hi(.LC2)
	lw	a2,%lo(.LC2)(a3)
	lw	a3,%lo(.LC2+4)(a3)
	mv	a0,a4
	mv	a1,a5
	call	__ltdf2
	mv	a5,a0
	blt	a5,zero,.L69
	li	s1,0
.L69:
	andi	a5,s1,0xff
.L66:
	mv	a0,a5
	lw	ra,44(sp)
	lw	s0,40(sp)
	lw	s1,36(sp)
	addi	sp,sp,48
	jr	ra
	.size	verify_benchmark, .-verify_benchmark
	.align	2
	.globl	initialise_benchmark
	.type	initialise_benchmark, @function
initialise_benchmark:
	addi	sp,sp,-16
	sw	ra,12(sp)
	sw	s0,8(sp)
	addi	s0,sp,16
	nop
	lw	ra,12(sp)
	lw	s0,8(sp)
	addi	sp,sp,16
	jr	ra
	.size	initialise_benchmark, .-initialise_benchmark
	.align	2
	.globl	warm_caches
	.type	warm_caches, @function
warm_caches:
	addi	sp,sp,-48
	sw	ra,44(sp)
	sw	s0,40(sp)
	addi	s0,sp,48
	sw	a0,-36(s0)
	lw	a0,-36(s0)
	call	benchmark_body
	sw	a0,-20(s0)
	nop
	lw	ra,44(sp)
	lw	s0,40(sp)
	addi	sp,sp,48
	jr	ra
	.size	warm_caches, .-warm_caches
	.align	2
	.globl	benchmark
	.type	benchmark, @function
benchmark:
	addi	sp,sp,-16
	sw	ra,12(sp)
	sw	s0,8(sp)
	addi	s0,sp,16
	li	a0,555
	call	benchmark_body
	mv	a5,a0
	mv	a0,a5
	lw	ra,12(sp)
	lw	s0,8(sp)
	addi	sp,sp,16
	jr	ra
	.size	benchmark, .-benchmark
	.align	2
	.type	benchmark_body, @function
benchmark_body:
	addi	sp,sp,-48
	sw	ra,44(sp)
	sw	s0,40(sp)
	addi	s0,sp,48
	sw	a0,-36(s0)
	sw	zero,-20(s0)
	j	.L76
.L77:
	lui	a5,%hi(.LC1)
	lw	a5,%lo(.LC1)(a5)
	sw	a5,-24(s0)
	lui	a5,%hi(a)
	addi	a5,a5,%lo(a)
	lui	a4,%hi(a_ref)
	addi	a4,a4,%lo(a_ref)
	lw	t3,0(a4)
	lw	t1,4(a4)
	lw	a7,8(a4)
	lw	a6,12(a4)
	lw	a0,16(a4)
	lw	a1,20(a4)
	lw	a2,24(a4)
	lw	a3,28(a4)
	sw	t3,0(a5)
	sw	t1,4(a5)
	sw	a7,8(a5)
	sw	a6,12(a5)
	sw	a0,16(a5)
	sw	a1,20(a5)
	sw	a2,24(a5)
	sw	a3,28(a5)
	lw	a4,32(a4)
	sw	a4,32(a5)
	lw	a2,-24(s0)
	li	a1,3
	li	a0,3
	call	minver
	lui	a5,%hi(d)
	addi	a5,a5,%lo(d)
	lui	a4,%hi(a)
	addi	a4,a4,%lo(a)
	lw	t3,0(a4)
	lw	t1,4(a4)
	lw	a7,8(a4)
	lw	a6,12(a4)
	lw	a0,16(a4)
	lw	a1,20(a4)
	lw	a2,24(a4)
	lw	a3,28(a4)
	sw	t3,0(a5)
	sw	t1,4(a5)
	sw	a7,8(a5)
	sw	a6,12(a5)
	sw	a0,16(a5)
	sw	a1,20(a5)
	sw	a2,24(a5)
	sw	a3,28(a5)
	lw	a4,32(a4)
	sw	a4,32(a5)
	lui	a5,%hi(a)
	addi	a5,a5,%lo(a)
	lui	a4,%hi(a_ref)
	addi	a4,a4,%lo(a_ref)
	lw	t3,0(a4)
	lw	t1,4(a4)
	lw	a7,8(a4)
	lw	a6,12(a4)
	lw	a0,16(a4)
	lw	a1,20(a4)
	lw	a2,24(a4)
	lw	a3,28(a4)
	sw	t3,0(a5)
	sw	t1,4(a5)
	sw	a7,8(a5)
	sw	a6,12(a5)
	sw	a0,16(a5)
	sw	a1,20(a5)
	sw	a2,24(a5)
	sw	a3,28(a5)
	lw	a4,32(a4)
	sw	a4,32(a5)
	li	a3,3
	li	a2,3
	li	a1,3
	li	a0,3
	call	mmul
	lw	a5,-20(s0)
	addi	a5,a5,1
	sw	a5,-20(s0)
.L76:
	lw	a4,-20(s0)
	lw	a5,-36(s0)
	blt	a4,a5,.L77
	li	a5,0
	mv	a0,a5
	lw	ra,44(sp)
	lw	s0,40(sp)
	addi	sp,sp,48
	jr	ra
	.size	benchmark_body, .-benchmark_body
	.data
	.align	2
	.type	c_exp.1, @object
	.size	c_exp.1, 36
c_exp.1:
	.word	-1042808832
	.word	1104150528
	.word	-1049624576
	.word	-1042808832
	.word	-1054867456
	.word	1107558400
	.word	-1038352384
	.word	1105199104
	.word	-1056964608
	.align	2
	.type	d_exp.0, @object
	.size	d_exp.0, 36
d_exp.0:
	.word	1040746632
	.word	-1102263094
	.word	1049135238
	.word	-1090183498
	.word	1038621518
	.word	1057411998
	.word	1056293514
	.word	-1095216664
	.word	1025758984
	.section	.rodata
	.align	2
.LC0:
	.word	1065353216
	.align	2
.LC1:
	.word	897988541
	.align	3
.LC2:
	.word	-1998362383
	.word	1055193269
	.align	3
.LC3:
	.word	13249115
	.word	1076931243
	.globl	__truncdfsf2
	.globl	__adddf3
	.globl	__ltdf2
	.globl	__extendsfdf2
	.globl	__subsf3
	.globl	__nesf2
	.globl	__divsf3
	.globl	__gtsf2
	.globl	__lesf2
	.globl	__addsf3
	.globl	__mulsf3
	.globl	__gesf2
	.ident	"GCC: (g1b306039a) 15.1.0"
	.section	.note.GNU-stack,"",@progbits
