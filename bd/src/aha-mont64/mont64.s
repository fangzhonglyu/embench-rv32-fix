	.file	"mont64.c"
	.option nopic
	.attribute arch, "rv32i2p1_m2p0_zicsr2p0_zifencei2p0_zmmul1p0"
	.attribute unaligned_access, 0
	.attribute stack_align, 16
	.text
	.align	2
	.globl	mulul64
	.type	mulul64, @function
mulul64:
	addi	sp,sp,-192
	sw	ra,188(sp)
	sw	s0,184(sp)
	sw	s2,180(sp)
	sw	s3,176(sp)
	sw	s4,172(sp)
	sw	s5,168(sp)
	sw	s6,164(sp)
	sw	s7,160(sp)
	sw	s8,156(sp)
	sw	s9,152(sp)
	sw	s10,148(sp)
	sw	s11,144(sp)
	addi	s0,sp,192
	sw	a0,-136(s0)
	sw	a1,-132(s0)
	sw	a2,-144(s0)
	sw	a3,-140(s0)
	sw	a4,-148(s0)
	sw	a5,-152(s0)
	lw	a5,-132(s0)
	srli	a5,a5,0
	sw	a5,-160(s0)
	sw	zero,-156(s0)
	lw	a4,-160(s0)
	lw	a5,-156(s0)
	sw	a4,-56(s0)
	sw	a5,-52(s0)
	lw	a5,-136(s0)
	andi	s10,a5,-1
	lw	a5,-132(s0)
	andi	s11,a5,0
	sw	s10,-64(s0)
	sw	s11,-60(s0)
	lw	a5,-140(s0)
	srli	a5,a5,0
	sw	a5,-168(s0)
	sw	zero,-164(s0)
	lw	a4,-168(s0)
	lw	a5,-164(s0)
	sw	a4,-72(s0)
	sw	a5,-68(s0)
	lw	a5,-144(s0)
	andi	s8,a5,-1
	lw	a5,-140(s0)
	andi	s9,a5,0
	sw	s8,-80(s0)
	sw	s9,-76(s0)
	lw	a4,-60(s0)
	lw	a5,-80(s0)
	mul	a4,a4,a5
	lw	a3,-76(s0)
	lw	a5,-64(s0)
	mul	a5,a3,a5
	add	a3,a4,a5
	lw	a4,-64(s0)
	lw	a5,-80(s0)
	mul	a2,a4,a5
	mulhu	t6,a4,a5
	mv	t5,a2
	add	a5,a3,t6
	mv	t6,a5
	sw	t5,-88(s0)
	sw	t6,-84(s0)
	sw	t5,-88(s0)
	sw	t6,-84(s0)
	lw	a5,-88(s0)
	andi	s6,a5,-1
	lw	a5,-84(s0)
	andi	s7,a5,0
	sw	s6,-96(s0)
	sw	s7,-92(s0)
	lw	a5,-84(s0)
	srli	a5,a5,0
	sw	a5,-176(s0)
	sw	zero,-172(s0)
	lw	a4,-176(s0)
	lw	a5,-172(s0)
	sw	a4,-104(s0)
	sw	a5,-100(s0)
	lw	a4,-52(s0)
	lw	a5,-80(s0)
	mul	a4,a4,a5
	lw	a3,-76(s0)
	lw	a5,-56(s0)
	mul	a5,a3,a5
	add	a3,a4,a5
	lw	a4,-56(s0)
	lw	a5,-80(s0)
	mul	a2,a4,a5
	mulhu	t4,a4,a5
	mv	t3,a2
	add	a5,a3,t4
	mv	t4,a5
	lw	a2,-104(s0)
	lw	a3,-100(s0)
	add	a4,a2,t3
	mv	a1,a4
	sltu	a1,a1,a2
	add	a5,a3,t4
	add	a3,a1,a5
	mv	a5,a3
	sw	a4,-88(s0)
	sw	a5,-84(s0)
	lw	a5,-88(s0)
	andi	s4,a5,-1
	lw	a5,-84(s0)
	andi	s5,a5,0
	sw	s4,-112(s0)
	sw	s5,-108(s0)
	lw	a5,-84(s0)
	srli	a5,a5,0
	sw	a5,-184(s0)
	sw	zero,-180(s0)
	lw	a4,-184(s0)
	lw	a5,-180(s0)
	sw	a4,-120(s0)
	sw	a5,-116(s0)
	lw	a4,-60(s0)
	lw	a5,-72(s0)
	mul	a4,a4,a5
	lw	a3,-68(s0)
	lw	a5,-64(s0)
	mul	a5,a3,a5
	add	a3,a4,a5
	lw	a4,-64(s0)
	lw	a5,-72(s0)
	mul	a2,a4,a5
	mulhu	t2,a4,a5
	mv	t1,a2
	add	a5,a3,t2
	mv	t2,a5
	lw	a2,-112(s0)
	lw	a3,-108(s0)
	add	a4,a2,t1
	mv	a1,a4
	sltu	a1,a1,a2
	add	a5,a3,t2
	add	a3,a1,a5
	mv	a5,a3
	sw	a4,-88(s0)
	sw	a5,-84(s0)
	lw	a5,-84(s0)
	srli	a5,a5,0
	sw	a5,-192(s0)
	sw	zero,-188(s0)
	lw	a4,-192(s0)
	lw	a5,-188(s0)
	sw	a4,-104(s0)
	sw	a5,-100(s0)
	lw	a5,-88(s0)
	slli	s3,a5,0
	li	s2,0
	lw	a2,-96(s0)
	lw	a3,-92(s0)
	add	a4,s2,a2
	mv	a1,a4
	sltu	a1,a1,s2
	add	a5,s3,a3
	add	a3,a1,a5
	mv	a5,a3
	lw	a3,-152(s0)
	sw	a4,0(a3)
	sw	a5,4(a3)
	lw	a4,-52(s0)
	lw	a5,-72(s0)
	mul	a4,a4,a5
	lw	a3,-68(s0)
	lw	a5,-56(s0)
	mul	a5,a3,a5
	add	a3,a4,a5
	lw	a4,-56(s0)
	lw	a5,-72(s0)
	mul	a2,a4,a5
	mulhu	a7,a4,a5
	mv	a6,a2
	add	a5,a3,a7
	mv	a7,a5
	lw	a2,-120(s0)
	lw	a3,-116(s0)
	add	a4,a6,a2
	mv	a1,a4
	sltu	a1,a1,a6
	add	a5,a7,a3
	add	a3,a1,a5
	mv	a5,a3
	mv	a2,a4
	mv	a3,a5
	lw	a0,-104(s0)
	lw	a1,-100(s0)
	add	a4,a2,a0
	mv	a6,a4
	sltu	a6,a6,a2
	add	a5,a3,a1
	add	a3,a6,a5
	mv	a5,a3
	lw	a3,-148(s0)
	sw	a4,0(a3)
	sw	a5,4(a3)
	nop
	lw	ra,188(sp)
	lw	s0,184(sp)
	lw	s2,180(sp)
	lw	s3,176(sp)
	lw	s4,172(sp)
	lw	s5,168(sp)
	lw	s6,164(sp)
	lw	s7,160(sp)
	lw	s8,156(sp)
	lw	s9,152(sp)
	lw	s10,148(sp)
	lw	s11,144(sp)
	addi	sp,sp,192
	jr	ra
	.size	mulul64, .-mulul64
	.align	2
	.globl	modul64
	.type	modul64, @function
modul64:
	addi	sp,sp,-64
	sw	ra,60(sp)
	sw	s0,56(sp)
	addi	s0,sp,64
	sw	a0,-40(s0)
	sw	a1,-36(s0)
	sw	a2,-48(s0)
	sw	a3,-44(s0)
	sw	a4,-56(s0)
	sw	a5,-52(s0)
	li	a4,1
	li	a5,0
	sw	a4,-24(s0)
	sw	a5,-20(s0)
	j	.L4
.L7:
	lw	a4,-40(s0)
	lw	a5,-36(s0)
	srai	a3,a5,31
	sw	a3,-32(s0)
	srai	a5,a5,31
	sw	a5,-28(s0)
	lw	a5,-40(s0)
	srli	a5,a5,31
	lw	a4,-36(s0)
	slli	a7,a4,1
	add	a7,a5,a7
	lw	a5,-40(s0)
	slli	a6,a5,1
	lw	a5,-44(s0)
	srli	t3,a5,31
	li	t4,0
	or	a5,a6,t3
	sw	a5,-40(s0)
	or	a5,a7,t4
	sw	a5,-36(s0)
	lw	a5,-48(s0)
	srli	a5,a5,31
	lw	a4,-44(s0)
	slli	t2,a4,1
	add	t2,a5,t2
	lw	a5,-48(s0)
	slli	t1,a5,1
	sw	t1,-48(s0)
	sw	t2,-44(s0)
	lw	a4,-32(s0)
	lw	a5,-28(s0)
	lw	a3,-40(s0)
	or	t5,a3,a4
	lw	a3,-36(s0)
	or	t6,a3,a5
	lw	a5,-52(s0)
	mv	a4,t6
	bgtu	a5,a4,.L5
	lw	a5,-52(s0)
	mv	a4,t6
	bne	a5,a4,.L10
	lw	a5,-56(s0)
	mv	a4,t5
	bgtu	a5,a4,.L5
.L10:
	lw	a2,-40(s0)
	lw	a3,-36(s0)
	lw	a0,-56(s0)
	lw	a1,-52(s0)
	sub	a4,a2,a0
	mv	t0,a4
	sgtu	t0,t0,a2
	sub	a5,a3,a1
	sub	a3,a5,t0
	mv	a5,a3
	sw	a4,-40(s0)
	sw	a5,-36(s0)
	lw	a2,-48(s0)
	lw	a3,-44(s0)
	li	a0,1
	li	a1,0
	add	a4,a2,a0
	mv	t0,a4
	sltu	t0,t0,a2
	add	a5,a3,a1
	add	a3,t0,a5
	mv	a5,a3
	sw	a4,-48(s0)
	sw	a5,-44(s0)
.L5:
	lw	a2,-24(s0)
	lw	a3,-20(s0)
	li	a0,1
	li	a1,0
	add	a4,a2,a0
	mv	t0,a4
	sltu	t0,t0,a2
	add	a5,a3,a1
	add	a3,t0,a5
	mv	a5,a3
	sw	a4,-24(s0)
	sw	a5,-20(s0)
.L4:
	lw	a5,-20(s0)
	bgt	a5,zero,.L11
	lw	a5,-20(s0)
	bne	a5,zero,.L7
	lw	a4,-24(s0)
	li	a5,64
	bleu	a4,a5,.L7
.L11:
	lw	a4,-40(s0)
	lw	a5,-36(s0)
	mv	a0,a4
	mv	a1,a5
	lw	ra,60(sp)
	lw	s0,56(sp)
	addi	sp,sp,64
	jr	ra
	.size	modul64, .-modul64
	.align	2
	.globl	montmul
	.type	montmul, @function
montmul:
	addi	sp,sp,-144
	sw	ra,140(sp)
	sw	s0,136(sp)
	sw	s2,132(sp)
	sw	s3,128(sp)
	sw	s4,124(sp)
	sw	s5,120(sp)
	sw	s6,116(sp)
	sw	s7,112(sp)
	sw	s8,108(sp)
	sw	s9,104(sp)
	sw	s10,100(sp)
	sw	s11,96(sp)
	addi	s0,sp,144
	sw	a0,-120(s0)
	sw	a1,-116(s0)
	sw	a2,-128(s0)
	sw	a3,-124(s0)
	sw	a4,-136(s0)
	sw	a5,-132(s0)
	sw	a6,-144(s0)
	sw	a7,-140(s0)
	addi	a5,s0,-96
	addi	a4,s0,-88
	lw	a2,-128(s0)
	lw	a3,-124(s0)
	lw	a0,-120(s0)
	lw	a1,-116(s0)
	call	mulul64
	lw	a4,-96(s0)
	lw	a5,-92(s0)
	lw	a3,-140(s0)
	mul	a2,a3,a4
	lw	a3,-144(s0)
	mul	a3,a3,a5
	add	a2,a2,a3
	lw	a3,-144(s0)
	mul	a1,a3,a4
	mulhu	s3,a3,a4
	mv	s2,a1
	add	a5,a2,s3
	mv	s3,a5
	sw	s2,-64(s0)
	sw	s3,-60(s0)
	sw	s2,-64(s0)
	sw	s3,-60(s0)
	addi	a5,s0,-112
	addi	a4,s0,-104
	lw	a2,-136(s0)
	lw	a3,-132(s0)
	lw	a0,-64(s0)
	lw	a1,-60(s0)
	call	mulul64
	lw	a2,-96(s0)
	lw	a3,-92(s0)
	lw	a0,-112(s0)
	lw	a1,-108(s0)
	add	a4,a2,a0
	mv	a6,a4
	sltu	a6,a6,a2
	add	a5,a3,a1
	add	a3,a6,a5
	mv	a5,a3
	sw	a4,-72(s0)
	sw	a5,-68(s0)
	lw	a2,-88(s0)
	lw	a3,-84(s0)
	lw	a0,-104(s0)
	lw	a1,-100(s0)
	add	a4,a2,a0
	mv	a6,a4
	sltu	a6,a6,a2
	add	a5,a3,a1
	add	a3,a6,a5
	mv	a5,a3
	sw	a4,-56(s0)
	sw	a5,-52(s0)
	lw	a4,-96(s0)
	lw	a5,-92(s0)
	lw	a3,-68(s0)
	mv	a2,a5
	bltu	a3,a2,.L22
	lw	a3,-68(s0)
	mv	a2,a5
	bne	a3,a2,.L13
	lw	a3,-72(s0)
	mv	a5,a4
	bgeu	a3,a5,.L13
.L22:
	lw	a2,-56(s0)
	lw	a3,-52(s0)
	li	a0,1
	li	a1,0
	add	a4,a2,a0
	mv	a6,a4
	sltu	a6,a6,a2
	add	a5,a3,a1
	add	a3,a6,a5
	mv	a5,a3
	sw	a4,-56(s0)
	sw	a5,-52(s0)
.L13:
	lw	a4,-88(s0)
	lw	a5,-84(s0)
	li	a2,1
	lw	a3,-52(s0)
	mv	a1,a5
	bltu	a3,a1,.L15
	lw	a3,-52(s0)
	mv	a1,a5
	bne	a3,a1,.L16
	lw	a3,-56(s0)
	mv	a5,a4
	bltu	a3,a5,.L15
.L16:
	li	a2,0
.L15:
	andi	a5,a2,0xff
	mv	a0,a5
	lw	a4,-88(s0)
	lw	a5,-84(s0)
	lw	a3,-56(s0)
	xor	s8,a3,a4
	lw	a3,-52(s0)
	xor	s9,a3,a5
	or	a5,s8,s9
	seqz	a5,a5
	andi	a3,a5,0xff
	lw	a4,-96(s0)
	lw	a5,-92(s0)
	li	a1,1
	lw	a2,-68(s0)
	mv	a6,a5
	bltu	a2,a6,.L17
	lw	a2,-68(s0)
	mv	a6,a5
	bne	a2,a6,.L18
	lw	a2,-72(s0)
	mv	a5,a4
	bltu	a2,a5,.L17
.L18:
	li	a1,0
.L17:
	andi	a5,a1,0xff
	and	a5,a3,a5
	andi	a5,a5,0xff
	or	a5,a0,a5
	sw	a5,-80(s0)
	srai	a5,a5,31
	sw	a5,-76(s0)
	lw	a4,-56(s0)
	lw	a5,-52(s0)
	sw	a4,-72(s0)
	sw	a5,-68(s0)
	li	a5,0
	li	a6,0
	sw	a5,-56(s0)
	sw	a6,-52(s0)
	li	a3,1
	lw	a4,-132(s0)
	lw	a5,-68(s0)
	bgtu	a4,a5,.L20
	lw	a4,-132(s0)
	lw	a5,-68(s0)
	bne	a4,a5,.L19
	lw	a4,-136(s0)
	lw	a5,-72(s0)
	bleu	a4,a5,.L19
.L20:
	li	a3,0
.L19:
	andi	a5,a3,0xff
	mv	s10,a5
	li	s11,0
	lw	a5,-80(s0)
	or	s6,a5,s10
	lw	a5,-76(s0)
	or	s7,a5,s11
	li	a4,0
	li	a5,0
	sub	a2,a4,s6
	mv	a1,a2
	sgtu	a1,a1,a4
	sub	a3,a5,s7
	sub	a5,a3,a1
	mv	a3,a5
	mv	a4,a2
	mv	a5,a3
	lw	a3,-136(s0)
	and	s4,a3,a4
	lw	a3,-132(s0)
	and	s5,a3,a5
	lw	a2,-72(s0)
	lw	a3,-68(s0)
	sub	a4,a2,s4
	mv	a1,a4
	sgtu	a1,a1,a2
	sub	a5,a3,s5
	sub	a3,a5,a1
	mv	a5,a3
	sw	a4,-72(s0)
	sw	a5,-68(s0)
	lw	a4,-72(s0)
	lw	a5,-68(s0)
	mv	a0,a4
	mv	a1,a5
	lw	ra,140(sp)
	lw	s0,136(sp)
	lw	s2,132(sp)
	lw	s3,128(sp)
	lw	s4,124(sp)
	lw	s5,120(sp)
	lw	s6,116(sp)
	lw	s7,112(sp)
	lw	s8,108(sp)
	lw	s9,104(sp)
	lw	s10,100(sp)
	lw	s11,96(sp)
	addi	sp,sp,144
	jr	ra
	.size	montmul, .-montmul
	.align	2
	.globl	xbinGCD
	.type	xbinGCD, @function
xbinGCD:
	addi	sp,sp,-112
	sw	ra,108(sp)
	sw	s0,104(sp)
	sw	s2,100(sp)
	sw	s3,96(sp)
	sw	s4,92(sp)
	sw	s5,88(sp)
	sw	s6,84(sp)
	sw	s7,80(sp)
	sw	s8,76(sp)
	sw	s9,72(sp)
	addi	s0,sp,112
	sw	a0,-88(s0)
	sw	a1,-84(s0)
	sw	a2,-96(s0)
	sw	a3,-92(s0)
	sw	a4,-100(s0)
	sw	a5,-104(s0)
	li	a4,1
	li	a5,0
	sw	a4,-56(s0)
	sw	a5,-52(s0)
	li	a4,0
	li	a5,0
	sw	a4,-64(s0)
	sw	a5,-60(s0)
	lw	a4,-88(s0)
	lw	a5,-84(s0)
	sw	a4,-72(s0)
	sw	a5,-68(s0)
	lw	a4,-96(s0)
	lw	a5,-92(s0)
	sw	a4,-80(s0)
	sw	a5,-76(s0)
	j	.L24
.L26:
	lw	a5,-84(s0)
	slli	a5,a5,31
	lw	a4,-88(s0)
	srli	t5,a4,1
	add	t5,a5,t5
	lw	a5,-84(s0)
	srli	t6,a5,1
	sw	t5,-88(s0)
	sw	t6,-84(s0)
	lw	a5,-56(s0)
	andi	s8,a5,1
	lw	a5,-52(s0)
	andi	s9,a5,0
	mv	a5,s8
	or	a5,a5,s9
	bne	a5,zero,.L25
	lw	a5,-52(s0)
	slli	a5,a5,31
	lw	a4,-56(s0)
	srli	s2,a4,1
	add	s2,a5,s2
	lw	a5,-52(s0)
	srli	s3,a5,1
	sw	s2,-56(s0)
	sw	s3,-52(s0)
	lw	a5,-60(s0)
	slli	a5,a5,31
	lw	a4,-64(s0)
	srli	s4,a4,1
	add	s4,a5,s4
	lw	a5,-60(s0)
	srli	s5,a5,1
	sw	s4,-64(s0)
	sw	s5,-60(s0)
	j	.L24
.L25:
	lw	a4,-56(s0)
	lw	a5,-80(s0)
	xor	t3,a4,a5
	lw	a4,-52(s0)
	lw	a5,-76(s0)
	xor	t4,a4,a5
	slli	a5,t4,31
	srli	a6,t3,1
	add	a6,a5,a6
	srli	a7,t4,1
	lw	a4,-56(s0)
	lw	a5,-80(s0)
	and	s6,a4,a5
	lw	a4,-52(s0)
	lw	a5,-76(s0)
	and	s7,a4,a5
	add	a4,a6,s6
	mv	a3,a4
	sltu	a3,a3,a6
	add	a5,a7,s7
	add	a3,a3,a5
	mv	a5,a3
	sw	a4,-56(s0)
	sw	a5,-52(s0)
	lw	a5,-60(s0)
	slli	a5,a5,31
	lw	a4,-64(s0)
	srli	t1,a4,1
	add	t1,a5,t1
	lw	a5,-60(s0)
	srli	t2,a5,1
	lw	a2,-72(s0)
	lw	a3,-68(s0)
	add	a4,a2,t1
	mv	a1,a4
	sltu	a1,a1,a2
	add	a5,a3,t2
	add	a3,a1,a5
	mv	a5,a3
	sw	a4,-64(s0)
	sw	a5,-60(s0)
.L24:
	lw	a5,-88(s0)
	lw	a4,-84(s0)
	or	a5,a5,a4
	bne	a5,zero,.L26
	lw	a3,-100(s0)
	lw	a4,-56(s0)
	lw	a5,-52(s0)
	sw	a4,0(a3)
	sw	a5,4(a3)
	lw	a3,-104(s0)
	lw	a4,-64(s0)
	lw	a5,-60(s0)
	sw	a4,0(a3)
	sw	a5,4(a3)
	nop
	lw	ra,108(sp)
	lw	s0,104(sp)
	lw	s2,100(sp)
	lw	s3,96(sp)
	lw	s4,92(sp)
	lw	s5,88(sp)
	lw	s6,84(sp)
	lw	s7,80(sp)
	lw	s8,76(sp)
	lw	s9,72(sp)
	addi	sp,sp,112
	jr	ra
	.size	xbinGCD, .-xbinGCD
	.local	in_a
	.comm	in_a,8,8
	.local	in_b
	.comm	in_b,8,8
	.local	in_m
	.comm	in_m,8,8
	.align	2
	.globl	warm_caches
	.type	warm_caches, @function
warm_caches:
	addi	sp,sp,-48
	sw	ra,44(sp)
	sw	s0,40(sp)
	addi	s0,sp,48
	sw	a0,-36(s0)
	lw	a0,-36(s0)
	call	benchmark_body
	sw	a0,-20(s0)
	nop
	lw	ra,44(sp)
	lw	s0,40(sp)
	addi	sp,sp,48
	jr	ra
	.size	warm_caches, .-warm_caches
	.align	2
	.globl	benchmark
	.type	benchmark, @function
benchmark:
	addi	sp,sp,-16
	sw	ra,12(sp)
	sw	s0,8(sp)
	addi	s0,sp,16
	li	a0,423
	call	benchmark_body
	mv	a5,a0
	mv	a0,a5
	lw	ra,12(sp)
	lw	s0,8(sp)
	addi	sp,sp,16
	jr	ra
	.size	benchmark, .-benchmark
	.align	2
	.type	benchmark_body, @function
benchmark_body:
	addi	sp,sp,-176
	sw	ra,172(sp)
	sw	s0,168(sp)
	sw	s2,164(sp)
	sw	s3,160(sp)
	sw	s4,156(sp)
	sw	s5,152(sp)
	sw	s6,148(sp)
	sw	s7,144(sp)
	addi	s0,sp,176
	sw	a0,-164(s0)
	sw	zero,-36(s0)
	j	.L33
.L38:
	sw	zero,-40(s0)
	lui	a5,%hi(in_m)
	lw	a4,%lo(in_m)(a5)
	lw	a5,%lo(in_m+4)(a5)
	sw	a4,-48(s0)
	sw	a5,-44(s0)
	lui	a5,%hi(in_b)
	lw	a4,%lo(in_b)(a5)
	lw	a5,%lo(in_b+4)(a5)
	sw	a4,-56(s0)
	sw	a5,-52(s0)
	lui	a5,%hi(in_a)
	lw	a4,%lo(in_a)(a5)
	lw	a5,%lo(in_a+4)(a5)
	sw	a4,-64(s0)
	sw	a5,-60(s0)
	addi	a5,s0,-120
	addi	a4,s0,-112
	lw	a2,-56(s0)
	lw	a3,-52(s0)
	lw	a0,-64(s0)
	lw	a1,-60(s0)
	call	mulul64
	lw	a0,-112(s0)
	lw	a1,-108(s0)
	lw	a2,-120(s0)
	lw	a3,-116(s0)
	lw	a4,-48(s0)
	lw	a5,-44(s0)
	call	modul64
	sw	a0,-72(s0)
	sw	a1,-68(s0)
	addi	a5,s0,-120
	addi	a4,s0,-112
	lw	a2,-72(s0)
	lw	a3,-68(s0)
	lw	a0,-72(s0)
	lw	a1,-68(s0)
	call	mulul64
	lw	a0,-112(s0)
	lw	a1,-108(s0)
	lw	a2,-120(s0)
	lw	a3,-116(s0)
	lw	a4,-48(s0)
	lw	a5,-44(s0)
	call	modul64
	sw	a0,-72(s0)
	sw	a1,-68(s0)
	addi	a5,s0,-120
	addi	a4,s0,-112
	lw	a2,-72(s0)
	lw	a3,-68(s0)
	lw	a0,-72(s0)
	lw	a1,-68(s0)
	call	mulul64
	lw	a0,-112(s0)
	lw	a1,-108(s0)
	lw	a2,-120(s0)
	lw	a3,-116(s0)
	lw	a4,-48(s0)
	lw	a5,-44(s0)
	call	modul64
	sw	a0,-72(s0)
	sw	a1,-68(s0)
	li	a4,0
	li	a5,-2147483648
	sw	a4,-80(s0)
	sw	a5,-76(s0)
	addi	a5,s0,-152
	addi	a4,s0,-144
	lw	a2,-48(s0)
	lw	a3,-44(s0)
	lw	a0,-80(s0)
	lw	a1,-76(s0)
	call	xbinGCD
	lw	a4,-144(s0)
	lw	a5,-140(s0)
	lw	a3,-80(s0)
	mul	a2,a3,a5
	lw	a3,-76(s0)
	mul	a3,a3,a4
	add	a2,a2,a3
	lw	a3,-80(s0)
	mul	a1,a3,a4
	mulhu	s5,a3,a4
	mv	s4,a1
	add	a5,a2,s5
	mv	s5,a5
	srli	a5,s4,31
	slli	s3,s5,1
	add	s3,a5,s3
	slli	s2,s4,1
	lw	a4,-152(s0)
	lw	a5,-148(s0)
	lw	a3,-48(s0)
	mul	a2,a3,a5
	lw	a3,-44(s0)
	mul	a3,a3,a4
	add	a2,a2,a3
	lw	a3,-48(s0)
	mul	a1,a3,a4
	mulhu	s7,a3,a4
	mv	s6,a1
	add	a5,a2,s7
	mv	s7,a5
	sub	a4,s2,s6
	mv	a3,a4
	sgtu	a3,a3,s2
	sub	a5,s3,s7
	sub	a3,a5,a3
	mv	a5,a3
	mv	a2,a4
	mv	a3,a5
	mv	a4,a2
	li	a5,1
	bne	a4,a5,.L40
	mv	a5,a3
	beq	a5,zero,.L34
.L40:
	li	a5,1
	sw	a5,-40(s0)
.L34:
	lw	a4,-48(s0)
	lw	a5,-44(s0)
	li	a2,0
	li	a3,0
	lw	a0,-64(s0)
	lw	a1,-60(s0)
	call	modul64
	sw	a0,-88(s0)
	sw	a1,-84(s0)
	lw	a4,-48(s0)
	lw	a5,-44(s0)
	li	a2,0
	li	a3,0
	lw	a0,-56(s0)
	lw	a1,-52(s0)
	call	modul64
	sw	a0,-96(s0)
	sw	a1,-92(s0)
	lw	a4,-152(s0)
	lw	a5,-148(s0)
	mv	a6,a4
	mv	a7,a5
	lw	a4,-48(s0)
	lw	a5,-44(s0)
	lw	a2,-96(s0)
	lw	a3,-92(s0)
	lw	a0,-88(s0)
	lw	a1,-84(s0)
	call	montmul
	sw	a0,-104(s0)
	sw	a1,-100(s0)
	lw	a4,-152(s0)
	lw	a5,-148(s0)
	mv	a6,a4
	mv	a7,a5
	lw	a4,-48(s0)
	lw	a5,-44(s0)
	lw	a2,-104(s0)
	lw	a3,-100(s0)
	lw	a0,-104(s0)
	lw	a1,-100(s0)
	call	montmul
	sw	a0,-104(s0)
	sw	a1,-100(s0)
	lw	a4,-152(s0)
	lw	a5,-148(s0)
	mv	a6,a4
	mv	a7,a5
	lw	a4,-48(s0)
	lw	a5,-44(s0)
	lw	a2,-104(s0)
	lw	a3,-100(s0)
	lw	a0,-104(s0)
	lw	a1,-100(s0)
	call	montmul
	sw	a0,-104(s0)
	sw	a1,-100(s0)
	lw	a2,-144(s0)
	lw	a3,-140(s0)
	addi	a5,s0,-136
	addi	a4,s0,-128
	lw	a0,-104(s0)
	lw	a1,-100(s0)
	call	mulul64
	lw	a0,-128(s0)
	lw	a1,-124(s0)
	lw	a2,-136(s0)
	lw	a3,-132(s0)
	lw	a4,-48(s0)
	lw	a5,-44(s0)
	call	modul64
	sw	a0,-104(s0)
	sw	a1,-100(s0)
	lw	a4,-104(s0)
	lw	a5,-72(s0)
	bne	a4,a5,.L41
	lw	a4,-100(s0)
	lw	a5,-68(s0)
	beq	a4,a5,.L36
.L41:
	li	a5,1
	sw	a5,-40(s0)
.L36:
	lw	a5,-36(s0)
	addi	a5,a5,1
	sw	a5,-36(s0)
.L33:
	lw	a4,-36(s0)
	lw	a5,-164(s0)
	blt	a4,a5,.L38
	lw	a5,-40(s0)
	mv	a0,a5
	lw	ra,172(sp)
	lw	s0,168(sp)
	lw	s2,164(sp)
	lw	s3,160(sp)
	lw	s4,156(sp)
	lw	s5,152(sp)
	lw	s6,148(sp)
	lw	s7,144(sp)
	addi	sp,sp,176
	jr	ra
	.size	benchmark_body, .-benchmark_body
	.align	2
	.globl	initialise_benchmark
	.type	initialise_benchmark, @function
initialise_benchmark:
	addi	sp,sp,-16
	sw	ra,12(sp)
	sw	s0,8(sp)
	addi	s0,sp,16
	lui	a3,%hi(in_m)
	lui	a5,%hi(.LC0)
	lw	a4,%lo(.LC0)(a5)
	lw	a5,%lo(.LC0+4)(a5)
	sw	a4,%lo(in_m)(a3)
	sw	a5,%lo(in_m+4)(a3)
	lui	a3,%hi(in_b)
	lui	a5,%hi(.LC1)
	lw	a4,%lo(.LC1)(a5)
	lw	a5,%lo(.LC1+4)(a5)
	sw	a4,%lo(in_b)(a3)
	sw	a5,%lo(in_b+4)(a3)
	lui	a3,%hi(in_a)
	lui	a5,%hi(.LC2)
	lw	a4,%lo(.LC2)(a5)
	lw	a5,%lo(.LC2+4)(a5)
	sw	a4,%lo(in_a)(a3)
	sw	a5,%lo(in_a+4)(a3)
	nop
	lw	ra,12(sp)
	lw	s0,8(sp)
	addi	sp,sp,16
	jr	ra
	.size	initialise_benchmark, .-initialise_benchmark
	.align	2
	.globl	verify_benchmark
	.type	verify_benchmark, @function
verify_benchmark:
	addi	sp,sp,-32
	sw	ra,28(sp)
	sw	s0,24(sp)
	addi	s0,sp,32
	sw	a0,-20(s0)
	lw	a5,-20(s0)
	seqz	a5,a5
	andi	a5,a5,0xff
	mv	a0,a5
	lw	ra,28(sp)
	lw	s0,24(sp)
	addi	sp,sp,32
	jr	ra
	.size	verify_benchmark, .-verify_benchmark
	.section	.rodata
	.align	3
.LC0:
	.word	958986399
	.word	-85440217
	.align	3
.LC1:
	.word	-1187838605
	.word	343109103
	.align	3
.LC2:
	.word	-2027716625
	.word	88684321
	.ident	"GCC: (g1b306039a) 15.1.0"
	.section	.note.GNU-stack,"",@progbits
